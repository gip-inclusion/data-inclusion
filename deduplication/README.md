# `deduplication`

Ce dossier contient la *pipeline d'entra√Ænement* de notre mod√®le de d√©duplication. La d√©duplication ne concerne que les structures √† ce stade.

En partant des donn√©es structures en sortie via notre pipeline de donn√©es, nous produisons ici un mod√®le nous permettant d'identifier des doublons.

## Utilisation

```bash
python -m venv .venv && source .venv/bin/activate && pip install -U pip wheel setuptools && pip install -e .
```

La pipeline s'ex√©cute via le notebook `main.ipynb`. Par exemple dans vscode en ayant install√© l'extension `ms-toolsai.jupyter`.

## Architecture

Les donn√©es utilis√©es sont t√©l√©charg√©es depuis notre datalake interne [üëâ ici](https://console.scaleway.com/object-storage/buckets/fr-par/data-inclusion-datalake-prod-grand-titmouse/files/data/marts/).

```mermaid
graph LR
    structures@{shape: database, label: ./structures.parquet}
    labels@{shape: database, label: ./labels.json}
    model@{shape: database, label: ./model.bin}
    nouvelle-annotation@{shape: event, label: signalement doublon(s)}
    changement-schema@{shape: event, label: changement schema}
    changement-donnees@{shape: event, label: changement donn√©es}

    nouvelle-annotation --> pipeline-ml
    changement-schema --> pipeline-ml
    changement-donnees --> pipeline-ml

    subgraph pipeline-ml[pipeline d'entra√Ænement]
        direction LR

        labelisation@{shape: process, label: 1\. **lab√©lisation**}
        pretraitement@{shape: process, label: 2\. **pr√©traitement**}
        entrainement@{shape: process, label: 3\. **entra√Ænement/√©valuation**}

        structures --> labelisation --> labels --> entrainement
        structures --> pretraitement --> entrainement
        entrainement --> model
    end

    subgraph pipeline-data[pipeline de donn√©es]
        direction LR

        data@{shape: database, label: structures}
        doublons@{shape: documents}
        inference@{shape: process, label: inf√©rence}

        data --> inference
        model --> inference --> doublons
    end
```

La pipeline d'entra√Ænement est ex√©cut√©e manuellement, via le notebook `main.ipynb`.

La pipeline d'entra√Ænement produit un fichier binaire `model.bin`, qui sera charg√© dans la pipeline de donn√©es pour d√©doublonner r√©guli√®rement les structures.

La pipeline d'entra√Ænement comprend les √©tapes suivantes :

### 1. lab√©lisation

Nous maintenons une liste de paires de structures, qui ont √©t√© annot√©es manuellement. Chaque paire a √©t√© d√©clar√©e soit comme un doublon sans doute possible, soit comme bien distincte, soit incertaine. Ces annotations sont stock√©es actuellement dans le fichier `labels.json`. Afin de ne pas d√©pendre des donn√©es ou de leurs sch√©mas, et de ne pas exposer de donn√©es sensibles, seuls les identifiants (stables) sont inclus.

Lorsqu'une paire de structures est examin√©e, 3 cas de figures sont possibles :

* les structures ne correspondent pas du tout => **non doublon**
* les structures ont un lien, mais *pourrait √™tre distinctes* => **incertain**. Par exemple :
    * l'une est un sous-service de l'autre
    * ou d√©pend fortement de l'autre dans son fonctionnement (e.g. une mairie et son ccas)
* si les donn√©es correspondent (√† l'erreur de saisie pr√®s), et qu'il n'y a pas de doute => **doublon**

Toutes les paires incertaines devront id√©alement nous conduire :

* √† pr√©ciser notre d√©finition du concept de structure
* et/ou √† enrichir nos donn√©es pour permettre de les distinguer

### 2. pr√©traitement

Les donn√©es sont adapt√©es pour am√©liorer les performances du mod√®le. Ainsi on peut exclure certaines donn√©es aberrantes. Ou bien effectuer des nettoyages suppl√©mentaires qui n'ont pas vocation √† √™tre appliqu√©es en amont ou au contraire, qui n'ont pas encore √©t√© int√©gr√©es √† la pipeline de donn√©es.

### 3. entra√Ænement/√©valuation

Les donn√©es annot√©es sont r√©parties (pseudo-)al√©atoirement en deux : jeu d'entra√Ænement et de test.

Le seul algorithme actuellement consid√©r√© est celui propos√© par [dedupe](https://github.com/dedupeio/dedupe). Cet algorithme cr√©e des clusters de structures "proches".

A partir du jeu d'entra√Ænement, nous entrainons plusieurs versions en variant les param√®tres disponibles. Puis nous √©valuons et comparons les performances obtenues gr√¢ce au jeu de test.

Notre objectif est de minimiser l'impact n√©gatif cumul√© des doublons et de notre d√©duplication. Il y a un compromis √† trouver entre doublons non d√©tect√©s et faux doublons. A date, nous privil√©geons les doublons non d√©tect√©s.

Nous s√©lectionnons la version la plus int√©ressante selon ce compromis. Le mod√®le est stock√© dans le fichier `model.bin`. C'est ce fichier qui sera d√©ploy√© dans la pipeline de donn√©es.

A titre d'exploration, nous ex√©cutons le mod√®le sur la totalit√© du dataset pour explorer les clusters g√©n√©r√©s et en valider la coh√©rence : le nombre de clusters, la taille des clusters, les liens entre les diff√©rentes sources de donn√©es.

### 4. maintenance

Le mod√®le devra √™tre r√©entrain√© r√©guli√®rement pour tenir compte :

* des (non-)doublons remont√©s du terrain
* des √©volutions du sch√©ma
* de l'√©volution des donn√©es
