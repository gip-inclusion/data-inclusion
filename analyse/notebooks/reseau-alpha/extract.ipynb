{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from pathlib import Path\n",
    "import re\n",
    "import dateparser\n",
    "import trafilatura\n",
    "\n",
    "TESTING_WITH_LOCAL_FILES = True\n",
    "\n",
    "# URL = \"https://www.reseau-alpha.org/trouver-une-formation?form%5BcodePostal%5D%5B%5D=%7C91&form%5BcriteresScolarisation%5D=&form%5BniveauLinguistiqueVise%5D=&form%5Bprogramme%5D=&form%5BmotCle%5D=\"\n",
    "URL = 'file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/structure-list.html'\n",
    "\n",
    "# Live HTML (don't use too much!)\n",
    "# structure_base_url = 'https://www.reseau-alpha.org/structure/apprentissage-du-francais/'\n",
    "\n",
    "# Local HTML\n",
    "structure_base_url = \"file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/structures/\"\n",
    "formation_base_path = \"file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/services/\"\n",
    "\n",
    "# Structure avec antennes et formations : https://www.reseau-alpha.org/structure/apprentissage-du-francais/aries\n",
    "# Structure sans antenne et sans formation : https://www.reseau-alpha.org/structure/apprentissage-du-francais/acafi\n",
    "# Formation : https://www.reseau-alpha.org/structure/apprentissage-du-francais/aries/formation/francais-a-visee-professionnelle/b8a73-francais-a-visee-sociale-et-ou-professionnelle\n",
    "\n",
    "def html_to_markdown(s: str):\n",
    "    if s is None or s == \"\" :\n",
    "        return s\n",
    "    if type(s) == list:\n",
    "        s = \"<br/>\".join(s)\n",
    "    return trafilatura.extract(trafilatura.load_html(\"<html>\" + s + \"</html>\"))\n",
    "\n",
    "def clean_adresse(adresse_parts) -> {}:\n",
    "    code_postal = adresse = \"\"\n",
    "    clean_adresse_parts = {\n",
    "        \"adresse_entiere\": \"\",\n",
    "        \"adresse\": \"\",\n",
    "        \"code_postal\": \"\",\n",
    "        \"commune\": \"\"\n",
    "    }\n",
    "    for part in adresse_parts:\n",
    "        part = part.strip()\n",
    "        if re.match(r'^\\d', part):\n",
    "            if re.match(r'^\\d{5}', part):\n",
    "                split_address = part.split(\" - \")\n",
    "                clean_adresse_parts[\"code_postal\"] = split_address[0]\n",
    "                clean_adresse_parts[\"commune\"] = split_address[1]\n",
    "            else:\n",
    "                clean_adresse_parts[\"adresse\"] = part\n",
    "        clean_adresse_parts[\"adresse_entiere\"] += part + \", \"\n",
    "    return clean_adresse_parts\n",
    "\n",
    "def strip(maybe_string):\n",
    "    if type(maybe_string) == str:\n",
    "        return maybe_string.strip()\n",
    "    if maybe_string == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return maybe_string\n",
    "\n",
    "\n",
    "class AlphaSpider(scrapy.Spider):\n",
    "    name = \"alpha\"\n",
    "    custom_settings = {\n",
    "        \"DOWNLOAD_DELAY\": 0 if TESTING_WITH_LOCAL_FILES else 0.5\n",
    "    }\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            URL\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        formations_links = response.css('div#div-accordion-formation > div.contact-content a.readon')\n",
    "        \n",
    "        if TESTING_WITH_LOCAL_FILES:\n",
    "            for slug in formations_links.xpath('@href').getall():\n",
    "                next_page = formation_base_path + slug.split(\"/\")[-1]\n",
    "                yield scrapy.Request(next_page, callback=self.parse_formation)\n",
    "        else:\n",
    "            for a in formations_links:\n",
    "                yield response.follow(a, callback=self.parse_formation)\n",
    "\n",
    "\n",
    "        # for slug in dataslugs:\n",
    "        #     next_page = structure_base_url + slug\n",
    "        #     yield scrapy.Request(next_page, callback=self.parse_structure)\n",
    "    \n",
    "    # def parse_structure(self, response):\n",
    "        # slug = response.url.split('/')[-1]\n",
    "        # filename = f\"structures/{slug}\"\n",
    "        # Path(filename).write_bytes(response.body)\n",
    "\n",
    "\n",
    "        \n",
    "        # Adresse\n",
    "        # adresse_parts = response.css('div.lieu div.adresse::text')\n",
    "        # code_postal = adresse = \"\"\n",
    "        # clean_adresse_parts = []\n",
    "        # for part in adresse_parts:\n",
    "        #     print(part.strip())\n",
    "        #     if re.match(r'^\\d}', part):\n",
    "        #         if re.match(r'^\\d{5}', part):\n",
    "        #             code_postal = part.strip()[0:5]\n",
    "        #         else:\n",
    "        #             adresse = part.strip()\n",
    "        #     clean_adresse_parts.append(part.strip())\n",
    "        # print(\"\")\n",
    "\n",
    "\n",
    "        # # Téléphone\n",
    "        # telephone = response.css('div.lieu div.telephone > a::attr(href)').get()\n",
    "        # if type(telephone) == str:\n",
    "        #     telephone = telephone.strip()[4:]\n",
    "        # else:\n",
    "        #     telephone = \"\"\n",
    "\n",
    "        # yield {\n",
    "        #     \"structure_id\": slug,\n",
    "        #     \"structure_name\": response.css('div#structure > strong::text').get().strip(),\n",
    "        #     \"code_postal\": code_postal,\n",
    "        #     \"adresse\": adresse,\n",
    "        #     \"adresse_entière\": clean_adresse_parts,\n",
    "        #     \"site_web\": response.css('div.lieu div.facebook::text').get().strip(),\n",
    "        #     \"telephone\": telephone,\n",
    "\n",
    "        # }\n",
    "\n",
    "    def parse_formation(self, response):\n",
    "\n",
    "        # Downloading HTML content\n",
    "        # page = response.url.split(\"/\")[-1]\n",
    "        # filename = f\"services/{page}\"\n",
    "        # Path(filename).write_bytes(response.body)\n",
    "\n",
    "        formation_entete = response.css('div.entete')\n",
    "        formation_contenu = response.css('div.entete + div')\n",
    "        formation_contenu_col1 = response.css('div.entete + div > div:nth-child(1)')\n",
    "        formation_contenu_col2 = response.css('div.entete + div > div:nth-child(2)')\n",
    "        formation_inscription_info = formation_contenu_col2.css('div:nth-of-type(1)')\n",
    "        formation_inscription_contact = formation_contenu_col2.css('div:nth-of-type(2)')\n",
    "        formation_informations_pratiques = formation_contenu_col2.css('div:nth-of-type(3)')\n",
    "        formation_lieux_horaires = response.css('div#lieux-formation')\n",
    "\n",
    "\n",
    "        # SERVICE\n",
    "        service = {}\n",
    "\n",
    "        # Id\n",
    "        service[\"id\"] = response.url.split(\"/\")[-1]\n",
    "        \n",
    "        # Nom\n",
    "        service_nom_1 = strip(response.css(\"div.titre-element > strong::text\").get())\n",
    "        service_nom_2 = strip(response.css(\"a.underline.red-alpha + div::text\").get())\n",
    "        service[\"nom\"] = f\"{service_nom_1} ({service_nom_2})\"\n",
    "\n",
    "        # Date de màj\n",
    "        date_maj_fr = strip(response.css(\"a.underline.red-alpha + div + div::text\").get().split(\":\")[-1])\n",
    "        service[\"date_maj\"] = dateparser.parse(date_maj_fr).isoformat()\n",
    "        \n",
    "        # Description\n",
    "        contenu_objectif_public = formation_contenu_col1.css(\".row\").getall()\n",
    "        contenu_objectif_public += formation_informations_pratiques.get()\n",
    "        # les descriptions sont très longues et rendent difficiles le test des autres champs\n",
    "        # service[\"presentation_detail\"] = html_to_markdown(contenu_objectif_public)\n",
    "\n",
    "        # Lien vers la source\n",
    "        service[\"lien_source\"] = response.url\n",
    "\n",
    "        # Courriel\n",
    "        service[\"courriel\"] = strip(formation_inscription_contact.css('div.email.red-alpha > a::attr(href)').get()).split(\":\")[-1]\n",
    "\n",
    "        # Adresse\n",
    "        clean_adresse_parts = clean_adresse(formation_lieux_horaires.css(\"div.adresse::text\").getall())\n",
    "        service[\"adresse\"] = clean_adresse_parts[\"adresse\"]\n",
    "        service[\"code_postal\"] = clean_adresse_parts[\"code_postal\"]\n",
    "        service[\"commune\"] = clean_adresse_parts[\"commune\"]\n",
    "\n",
    "        # Téléphone\n",
    "        service[\"telephone\"] = \"\"\n",
    "        \n",
    "        # Contact nom prénom\n",
    "        service[\"contact_nom_prenom\"] = \"\"\n",
    "\n",
    "        # Thématiques\n",
    "        service[\"thematiques\"] = [\"apprendre-francais--suivre-formation\"]\n",
    "        if service_nom_2 == \"Français à visée professionnelle\":\n",
    "            service[\"thematiques\"].append(\"apprendre-francais--accompagnement-insertion-pro\")\n",
    "        if service_nom_2 == \"Français à visée sociale et communicative\":\n",
    "            service[\"thematiques\"].append(\"apprendre-francais--communiquer-vie-tous-les-jours\")\n",
    "\n",
    "        # Hard coded fields\n",
    "        service[\"zone_diffusion_type\"] = \"departement\"\n",
    "        service[\"zone_diffusion_code\"] = \"91\"\n",
    "        service[\"zone_diffusion_nom\"] = \"Essonne\"\n",
    "        service[\"types\"] = [\"formation\"]\n",
    "        service[\"cumulable\"] = True\n",
    "        service[\"contact_public\"] = True\n",
    "\n",
    "        \n",
    "        # STRUCTURE\n",
    "        structure = {}\n",
    "        # Nom de la structure\n",
    "        structure[\"nom\"] = strip(response.css(\"div.titre-element ~ a.underline.red-alpha::text\").get())\n",
    "        service[\"structure_id\"] = structure[\"id\"] = formation_entete.css(\"div.titre-element ~ a.underline.red-alpha::attr(href)\").get().split(\"/\")[-1]\n",
    "\n",
    "        yield service\n",
    "        \n",
    "    \n",
    "process = CrawlerProcess(settings={\n",
    "    \"FEEDS\": {\n",
    "        \"alpha.json\": {\n",
    "            \"format\": \"json\",\n",
    "            \"overwrite\": True,\n",
    "            \"ensure_ascii\": False,\n",
    "            'encoding': 'utf8',\n",
    "            'store_empty': False,\n",
    "            },\n",
    "        \"alpha.csv\": {\n",
    "            \"format\": \"csv\",\n",
    "            \"overwrite\": True,\n",
    "            'encoding': 'utf8',\n",
    "            },\n",
    "    },\n",
    "})\n",
    "process.crawl(AlphaSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
