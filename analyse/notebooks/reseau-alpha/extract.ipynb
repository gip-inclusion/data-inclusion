{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from pathlib import Path\n",
    "import re\n",
    "import dateparser\n",
    "import trafilatura\n",
    "\n",
    "TESTING_WITH_LOCAL_FILES = False\n",
    "\n",
    "# URL = \"https://www.reseau-alpha.org/trouver-une-formation?form%5BcodePostal%5D%5B%5D=%7C91&form%5BcriteresScolarisation%5D=&form%5BniveauLinguistiqueVise%5D=&form%5Bprogramme%5D=&form%5BmotCle%5D=\"\n",
    "URL = 'file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/structure-list.html'\n",
    "\n",
    "# Live HTML (don't use too much to avoid being banned!)\n",
    "# structure_base_url = 'https://www.reseau-alpha.org/structure/apprentissage-du-francais/'\n",
    "\n",
    "# Local HTML\n",
    "structure_base_url = \"file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/structures/\"\n",
    "formation_base_path = \"file:///home/colin/git/data-inclusion/analyse/notebooks/reseau-alpha/services/\"\n",
    "\n",
    "# Structure avec antennes et formations : https://www.reseau-alpha.org/structure/apprentissage-du-francais/aries\n",
    "# Structure sans antenne et sans formation : https://www.reseau-alpha.org/structure/apprentissage-du-francais/acafi\n",
    "# Formation : https://www.reseau-alpha.org/structure/apprentissage-du-francais/aries/formation/francais-a-visee-professionnelle/b8a73-francais-a-visee-sociale-et-ou-professionnelle\n",
    "\n",
    "def html_to_markdown(s: str):\n",
    "    if s is None or s == \"\" :\n",
    "        return s\n",
    "    if type(s) == list:\n",
    "        s = \"<br/>\".join(s)\n",
    "    return trafilatura.extract(trafilatura.load_html(\"<html>\" + s + \"</html>\"))\n",
    "\n",
    "def clean_adresse(adresses: list or scrapy.Selector) -> {} or []:\n",
    "    lieux = []\n",
    "    for adresse in adresses:\n",
    "        adresse_text_chunks = adresse.xpath('text()').getall()\n",
    "        clean_lieu = {\n",
    "            \"structure_service_adresse_entiere\": \"\",\n",
    "            \"structure_service_adresse\": \"\",\n",
    "            \"structure_service_code_postal\": \"\",\n",
    "            \"structure_service_commune\": \"\"\n",
    "        }\n",
    "        for part in adresse_text_chunks:\n",
    "            part = part.strip()\n",
    "            if re.match(r'^\\d', part):\n",
    "                if re.match(r'^\\d{5}', part):\n",
    "                    split_address = part.split(\" - \")\n",
    "                    clean_lieu[\"structure_service_code_postal\"] = split_address[0]\n",
    "                    clean_lieu[\"structure_service_commune\"] = split_address[1]\n",
    "                else:\n",
    "                    clean_lieu[\"structure_service_adresse\"] = part\n",
    "            clean_lieu[\"structure_service_adresse_entiere\"] += part + \", \"\n",
    "        lieux.append(clean_lieu)\n",
    "    return lieux\n",
    "\n",
    "def strip(maybe_string):\n",
    "    if type(maybe_string) == str:\n",
    "        return maybe_string.strip()\n",
    "    if maybe_string == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return maybe_string\n",
    "\n",
    "\n",
    "class AlphaSpider(scrapy.Spider):\n",
    "    name = \"alpha\"\n",
    "    custom_settings = {\n",
    "        \"DOWNLOAD_DELAY\": 0 if TESTING_WITH_LOCAL_FILES else 0.5\n",
    "    }\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            URL\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        formations_links = response.css('div#div-accordion-formation > div.contact-content a.readon')\n",
    "        \n",
    "        if TESTING_WITH_LOCAL_FILES:\n",
    "            for slug in formations_links.xpath('@href').getall():\n",
    "                next_page = formation_base_path + slug.split(\"/\")[-1]\n",
    "                yield scrapy.Request(next_page, callback=self.parse_formation)\n",
    "        else:\n",
    "            for a in formations_links:\n",
    "                yield response.follow(a, callback=self.parse_formation)\n",
    "\n",
    "\n",
    "        # for slug in dataslugs:\n",
    "        #     next_page = structure_base_url + slug\n",
    "        #     yield scrapy.Request(next_page, callback=self.parse_structure)\n",
    "\n",
    "    def parse_formation(self, response):\n",
    "\n",
    "        # Downloading HTML content\n",
    "        # page = response.url.split(\"/\")[-1]\n",
    "        # filename = f\"services/{page}\"\n",
    "        # Path(filename).write_bytes(response.body)\n",
    "\n",
    "        formation_entete = response.css('div.entete')\n",
    "        formation_contenu = response.css('div.entete + div')\n",
    "        formation_contenu_col1 = response.css('div.entete + div > div:nth-child(1)')\n",
    "        formation_contenu_col2 = response.css('div.entete + div > div:nth-child(2)')\n",
    "        formation_inscription_info = formation_contenu_col2.css('div:nth-of-type(1)')\n",
    "        formation_inscription_contact = formation_contenu_col2.css('div:nth-of-type(2)')\n",
    "        formation_informations_pratiques = formation_contenu_col2.css('div:nth-of-type(3)')\n",
    "        formation_lieux_horaires = response.css('div#lieux-formation')\n",
    "\n",
    "\n",
    "        # SERVICE\n",
    "        item = {}\n",
    "\n",
    "        # Id\n",
    "        item[\"id\"] = response.url.split(\"/\")[-1]\n",
    "        \n",
    "        # Nom\n",
    "        service_nom_1 = strip(response.css(\"div.titre-element > strong::text\").get())\n",
    "        service_nom_2 = strip(response.css(\"a.underline.red-alpha + div::text\").get())\n",
    "        item[\"nom\"] = f\"{service_nom_1} ({service_nom_2})\"\n",
    "\n",
    "        # Date de màj\n",
    "        date_maj_fr = strip(response.css(\"a.underline.red-alpha + div + div::text\").get().split(\":\")[-1])\n",
    "        item[\"date_maj\"] = dateparser.parse(date_maj_fr).isoformat()\n",
    "        \n",
    "        # Description\n",
    "        contenu_objectif_public = formation_contenu_col1.css(\".row\").getall()\n",
    "        contenu_objectif_public += formation_informations_pratiques.get()\n",
    "        # les descriptions sont très longues et rendent difficiles le test des autres champs\n",
    "        if TESTING_WITH_LOCAL_FILES is False:\n",
    "            item[\"presentation_detail\"] = html_to_markdown(contenu_objectif_public)\n",
    "\n",
    "        # Lien vers la source\n",
    "        item[\"lien_source\"] = response.url\n",
    "\n",
    "        # Courriel\n",
    "        item[\"courriel\"] = strip(formation_inscription_contact.css('div.email.red-alpha > a::attr(href)').get()).split(\":\")[-1]\n",
    "\n",
    "        # Adresse\n",
    "        clean_lieux = clean_adresse(formation_lieux_horaires.css(\"div.adresse\"))\n",
    "\n",
    "        # Téléphone\n",
    "        item[\"telephone\"] = \"\"\n",
    "        \n",
    "        # Contact nom prénom\n",
    "        item[\"contact_nom_prenom\"] = \"\"\n",
    "\n",
    "        # Thématiques\n",
    "        item[\"thematiques\"] = [\"apprendre-francais--suivre-formation\"]\n",
    "        if service_nom_2 == \"Français à visée professionnelle\":\n",
    "            item[\"thematiques\"].append(\"apprendre-francais--accompagnement-insertion-pro\")\n",
    "        if service_nom_2 == \"Français à visée sociale et communicative\":\n",
    "            item[\"thematiques\"].append(\"apprendre-francais--communiquer-vie-tous-les-jours\")\n",
    "\n",
    "        # Hard coded fields\n",
    "        item[\"zone_diffusion_type\"] = \"departement\"\n",
    "        item[\"zone_diffusion_code\"] = \"91\"\n",
    "        item[\"zone_diffusion_nom\"] = \"Essonne\"\n",
    "        item[\"types\"] = [\"formation\"]\n",
    "        item[\"cumulable\"] = True\n",
    "        item[\"contact_public\"] = True\n",
    "        item[\"modes_accueil\"] = [\"en-presentiel\"]\n",
    "\n",
    "        \n",
    "        # STRUCTURE\n",
    "        structure_link = formation_entete.css(\"div.titre-element ~ a.underline.red-alpha\")\n",
    "        # ID la structure\n",
    "        item[\"structure_id\"] = structure_link.xpath(\"@href\").get().split(\"/\")[-1]\n",
    "\n",
    "        # Une ligne/record de service par lieu\n",
    "        for lieu in clean_lieux:\n",
    "            print(lieu)\n",
    "            item = item | lieu\n",
    "            yield from response.follow_all(structure_link, callback=self.parse_structure, meta={\"item\": item}, dont_filter=True)\n",
    "    \n",
    "    def parse_structure(self, response):\n",
    "        item = response.meta.get(\"item\")\n",
    "        \n",
    "        # filename = f\"structures/{structure_id}\"\n",
    "        # Path(filename).write_bytes(response.body)\n",
    "\n",
    "        # Nom\n",
    "        item[\"structure_nom\"] = strip(response.css('div#structure > strong::text').get())\n",
    "\n",
    "        # Data màj\n",
    "        item[\"structure_date_maj\"] = strip(response.css('div.structures-dates > div:nth-child(2)').xpath('text()').get())\n",
    "        item[\"structure_date_maj\"] = item[\"structure_date_maj\"].split(\" : \")[-1]\n",
    "        item[\"structure_date_maj\"] = dateparser.parse(item[\"structure_date_maj\"]).isoformat()\n",
    "\n",
    "        # Adresse\n",
    "        # Sur le site Web, une structure a autant d'adresses qu'elle a de lieux pour ses services\n",
    "        # Certains services sont proposés sur toutes les adresses de la structure, certains non.\n",
    "\n",
    "        # Téléphone\n",
    "        telephone = response.css('div.lieu div.telephone > a::attr(href)').get()\n",
    "        if type(telephone) == str:\n",
    "            # Les numéro de téléphone sont préfixés par tel:\n",
    "            telephone = telephone.strip()[4:]\n",
    "        else:\n",
    "            telephone = \"\"\n",
    "        item[\"structure_telephone\"] = telephone\n",
    "        \n",
    "        # Site Web\n",
    "        item[\"structure_site_web\"] = strip(response.css('div.lieu div.facebook::text').get())\n",
    "\n",
    "        # Lien source\n",
    "        item[\"structure_lien_source\"] = response.url\n",
    "\n",
    "        # Labels\n",
    "        item[\"structure_labels_autres\"] = [\"reseau-alpha\"]\n",
    "\n",
    "        # Thématiques\n",
    "        item[\"structure_thematiques\"] = [\"apprendre-francais--suivre-formation\"]\n",
    "\n",
    "\n",
    "        yield item\n",
    "\n",
    "    \n",
    "process = CrawlerProcess(settings={\n",
    "    \"FEEDS\": {\n",
    "        \"alpha.json\": {\n",
    "            \"format\": \"json\",\n",
    "            \"overwrite\": True,\n",
    "            \"ensure_ascii\": False,\n",
    "            'encoding': 'utf8',\n",
    "            'store_empty': False,\n",
    "            },\n",
    "        \"alpha.csv\": {\n",
    "            \"format\": \"csv\",\n",
    "            \"overwrite\": True,\n",
    "            'encoding': 'utf8',\n",
    "            },\n",
    "    },\n",
    "})\n",
    "process.crawl(AlphaSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./alpha.csv', dtype = str, index_col=None)\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
