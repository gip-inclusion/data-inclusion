{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation du package de la pipeline pour utiliser\n",
    "# le code d'extraction de l'annuaire du service public\n",
    "\n",
    "!pip install -e ../../../pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch as es\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook illustre la siretisation d'un jeu de données grâce à l'indexation de la base sirene dans elasticsearch.\n",
    "\n",
    "Il faut préalablement avoir (ré)exécuté le dag d'import de la base sirene en local.\n",
    "\n",
    "Le jeu de données est l'ensemble des mairies de l'annuaire du service public, qui est déjà correctement sirétisé, afin d'évaluer l'heuristique de sirétisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "es_conn = es.Elasticsearch(\"http://localhost:9200\")  # utilisation de l'index local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(\n",
    "    nom: str,\n",
    "    adresse: str,\n",
    "    latitude: float,\n",
    "    longitude: float,\n",
    "    commune: str,\n",
    "):\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"filter\": [],\n",
    "            \"should\": [],\n",
    "            \"must\": [],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # query[\"bool\"][\"should\"].append({\"match\": {\"nom_complet\": nom}})\n",
    "    # query[\"bool\"][\"should\"].append({\"match\": {\"adresse_complete\": adresse}})\n",
    "    query[\"bool\"][\"should\"].append(\n",
    "        {\"match\": {\"libelle_commune_etablissement\": commune}}\n",
    "    )\n",
    "    query[\"bool\"][\"filter\"].append(\n",
    "        {\"match\": {\"activite_principale_etablissement\": \"84.11Z\"}}\n",
    "    )\n",
    "    query[\"bool\"][\"must\"].append(\n",
    "        {\n",
    "            \"geo_distance\": {\n",
    "                \"distance\": \"10km\",\n",
    "                \"coordonnees\": {\"lat\": latitude, \"lon\": longitude},\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    query[\"bool\"][\"filter\"].append(\n",
    "        {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\"match\": {\"categorie_juridique_unite_legale\": 7210}},\n",
    "                    {\"match\": {\"categorie_juridique_unite_legale\": 7312}},\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    query[\"bool\"][\"should\"].append(\n",
    "        {\"match\": {\"categorie_juridique_unite_legale\": 7210}}\n",
    "    )\n",
    "    query[\"bool\"][\"filter\"].append({\"match\": {\"etablissement_siege\": True}})\n",
    "\n",
    "    response = es_conn.search(index=\"siret\", query=query, size=10)\n",
    "    return (\n",
    "        next(iter(response[\"hits\"][\"hits\"]), None)\n",
    "        if \"hits\" in response and \"hits\" in response[\"hits\"]\n",
    "        else None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from data_inclusion.scripts.tasks import annuaire_du_service_public\n",
    "\n",
    "df = annuaire_du_service_public.read(Path(\"/home/vmttn/Downloads/all_latest.tar.bz2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[[\"id\", \"siret\", \"nom\", \"ancien_code_pivot\", \"adresse\"]]\n",
    "df1 = df1[df.ancien_code_pivot.str.contains(\"mairie\")]\n",
    "df1 = df1[[\"id\", \"siret\", \"nom\"]].merge(\n",
    "    pd.json_normalize(\n",
    "        df1.to_dict(orient=\"records\"), record_path=\"adresse\", meta=\"id\"\n",
    "    ).drop_duplicates(\"id\")[[\"id\", \"numero_voie\", \"nom_commune\", \"latitude\", \"longitude\"]],\n",
    "    on=\"id\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.merge(\n",
    "    df2.apply(\n",
    "        lambda row: find_matches(\n",
    "            row.nom,\n",
    "            row.numero_voie,\n",
    "            row.latitude,\n",
    "            row.longitude,\n",
    "            row.nom_commune,\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).apply(pd.Series),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# comparaison avec les résultats de la siretisation automatique\n",
    "\n",
    "df3[df3.siret != df3._id][[\"siret\", \"_id\", \"_score\", \"nom_commune\", \"nom\"]].sort_values(\"_score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
