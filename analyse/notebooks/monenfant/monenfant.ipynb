{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "departements=[\"11\", \"74\", \"91\"]\n",
    "\n",
    "assert os.environ['MONENFANT_HTML_DIR']\n",
    "\n",
    "def get_html_file_list() -> [str]:\n",
    "    html_file_list=[]\n",
    "    root_dir = Path(os.environ['MONENFANT_HTML_DIR'])\n",
    "    for filename in os.listdir(root_dir):\n",
    "        if filename.endswith(\".html\"):\n",
    "            html_file_uri = \"file://\" + str(root_dir / filename)\n",
    "            print(html_file_uri)\n",
    "            html_file_list.append(html_file_uri)\n",
    "    return html_file_list\n",
    "\n",
    "\n",
    "def get_code_postal(adresse: str):\n",
    "    re_code_postal = re.compile('^.*(?P<codepostal>\\d{5}).*$')\n",
    "    resultat = re_code_postal.match(adresse)\n",
    "    return resultat.groupdict()['codepostal']\n",
    "\n",
    "\n",
    "CRECHE_IDS = []\n",
    "CRECHE_DATA_SCRAPED_1 = []\n",
    "CRECHE_DUPLICATE_IDS = []\n",
    "CRECHE_BAD_DEPARTEMENT = []\n",
    "\n",
    "\n",
    "class CrechesSpider(scrapy.Spider):\n",
    "    name = \"monenfant\"\n",
    "        \n",
    "    start_urls=get_html_file_list()\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for creche in response.css(\"div.formulaire-content-liste > div.panel\"):\n",
    "            adresse_brute = creche.css(\"div.addresse-infos-structures-container > span::text\").get()\n",
    "            code_postal = get_code_postal(adresse_brute)\n",
    "            adresse_rue = adresse_brute.split(code_postal)[0].strip()\n",
    "            creche_id = creche.xpath(\"@id\").get()\n",
    "            \n",
    "            if creche_id not in CRECHE_IDS and code_postal[0:2] in departements :\n",
    "\n",
    "                creche_data = {\n",
    "                    \"id\": creche_id,\n",
    "                    \"nom\": creche.css(\"div.panel-head h5.panel-title::text\").get() || ,\n",
    "                    \"adresse\": adresse_rue,\n",
    "                    \"code_postal\": code_postal,\n",
    "                    \"telephone\": creche.css(\".infos-structures-column-phone a.infos-structures-lien::text\").get(),\n",
    "                    \"courriel\": creche.css(\"div[name='infos-mail'] a.infos-structures-lien::text\").get()\n",
    "                }\n",
    "            \n",
    "                CRECHE_DATA_SCRAPED_1.append(creche_data)\n",
    "                CRECHE_IDS.append(creche_id)\n",
    "                \n",
    "            if creche_id in CRECHE_IDS:\n",
    "                CRECHE_DUPLICATE_IDS.append(creche_id)\n",
    "                \n",
    "            if code_postal[0:2] not in departements:\n",
    "                CRECHE_BAD_DEPARTEMENT.append(creche_id)\n",
    "                \n",
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\": {\n",
    "            \"items.json\": {\"format\": \"json\"},\n",
    "        },\n",
    "        \"LOG_LEVEL\": \"ERROR\"\n",
    "    }\n",
    ")\n",
    "\n",
    "process.crawl(CrechesSpider)\n",
    "process.start() \n",
    "\n",
    "print(f\"Scraped {len(CRECHE_DATA_SCRAPED_1)} creches.\\n\n",
    "{len(CRECHE_DUPLICATE_IDS)} duplicate ids\\n\n",
    "{len(CRECHE_BAD_DEPARTEMENT)} creches in the wrong departement\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve more data\n",
    "\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "CRECHE_IDS_LEN = len(CRECHE_IDS)\n",
    "CRECHE_DATA_SCRAPED_2 = []\n",
    "\n",
    "print(f\"Retrieving the data of {CRECHE_IDS_LEN} cr√®ches...\")\n",
    "\n",
    "now = datetime.now()\n",
    "today = now.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "for i in range(0, CRECHE_IDS_LEN):\n",
    "    creche_id = CRECHE_IDS[i]\n",
    "    \n",
    "    url = 'https://monenfant.fr/web/guest/que-recherchez-vous?p_p_id=fr_monenfant_recherche_portlet_RecherchePortlet_INSTANCE_VnedXuapLnSM&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_resource_id=%2Frecherche%2Frechercher&p_p_cacheability=cacheLevelPage&_fr_monenfant_recherche_portlet_RecherchePortlet_INSTANCE_VnedXuapLnSM_cmd=get_structure_details'\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'data.inclusion@beta.gouv.fr',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Accept-Language': 'fr,en-US;q=0.7,en;q=0.3',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'Origin': 'https://monenfant.fr',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Referer': 'https://monenfant.fr/que-recherchez-vous/mode-d-accueil',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'Sec-GPC': '1'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        '_fr_monenfant_recherche_portlet_RecherchePortlet_INSTANCE_VnedXuapLnSM_id': creche_id,\n",
    "        '_fr_monenfant_recherche_portlet_RecherchePortlet_INSTANCE_VnedXuapLnSM_dureeRecherche': '345',\n",
    "        '_fr_monenfant_recherche_portlet_RecherchePortlet_INSTANCE_VnedXuapLnSM_dateDebutRecherche': today\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data).json()\n",
    "\n",
    "    formatted_creche_data = {\n",
    "        \"id\": creche_id,\n",
    "        \"avip\": response['avip'],\n",
    "        \"presentation_resume\": response['details']['presentation']['structureProjet'],\n",
    "        \"horaires_ouverture\": response['details']['infosPratiques']['jourHoraire'],\n",
    "        \"commune\": response['ville'],\n",
    "        \"site_web\": response['details']['website'],\n",
    "        \"labels_nationaux\": 'AVIP' if response['avip'] else \"\",\n",
    "        \"latitude\": response['latitude'],\n",
    "        \"longitude\": response['longitude'],\n",
    "        \"source\": \"monenfant\",\n",
    "        \"lien_source\": f\"https://monenfant.fr/que-recherchez-vous/{creche_id}\",\n",
    "        \"date_maj\": response['derniereModifDate']\n",
    "    }\n",
    "    \n",
    "    CRECHE_DATA_SCRAPED_2.append(formatted_creche_data)\n",
    "    print(str(i + 1), response['nom'])\n",
    "    time.sleep(0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.DataFrame(CRECHE_DATA_SCRAPED_1, dtype=str)\n",
    "df_1.set_index(\"id\", inplace=True)\n",
    "df_2 = pd.DataFrame(CRECHE_DATA_SCRAPED_2, dtype=str)\n",
    "df_2.set_index(\"id\", inplace=True)\n",
    "\n",
    "df_1.to_parquet(f'./scraped_from_html_{now.isoformat()}.parquet')\n",
    "df_2.to_parquet(f'./scraped_from_api_{now.isoformat()}.parquet')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.join(df_2)\n",
    "df.to_csv(f'./monenfant_{now.isoformat()}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
