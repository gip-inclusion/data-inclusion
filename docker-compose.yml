version: "3"

x-airflow-common:
  &airflow-common

  environment:
    &airflow-common-environment
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Paris
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    # AIRFLOW__CORE__FERNET_KEY:
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: 'false'
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow:airflow@airflow-db:5432/airflow
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 60
    AIRFLOW__WEBSERVER__WORKERS: 1

    # Connections
    AIRFLOW_CONN_PG: postgresql://data-inclusion:data-inclusion@target-db:5432/data-inclusion
    AIRFLOW_CONN_S3: aws://@/data-inclusion-lake?endpoint_url=http%3A%2F%2Fminio%3A9000&aws_access_key_id=minioadmin&aws_secret_access_key=minioadmin
    AIRFLOW_CONN_S3_SOURCES: ${AIRFLOW_CONN_S3_SOURCES}

    AIRFLOW_CONN_S3_LOGS: aws://@/data-inclusion-lake?endpoint_url=http%3A%2F%2Fminio%3A9000&aws_access_key_id=minioadmin&aws_secret_access_key=minioadmin
    AIRFLOW__LOGGING__REMOTE_LOGGING: True
    AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: s3://data-inclusion-lake/logs
    AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: s3_logs
    AIRFLOW__LOGGING__DELETE_LOCAL_LOGS: True

    # Variables
    AIRFLOW_VAR_DATAGOUV_API_KEY: ${AIRFLOW_VAR_DATAGOUV_API_KEY}
    AIRFLOW_VAR_DORA_API_TOKEN: ${AIRFLOW_VAR_DORA_API_TOKEN}
    AIRFLOW_VAR_EMPLOIS_API_TOKEN: ${AIRFLOW_VAR_EMPLOIS_API_TOKEN}
    AIRFLOW_VAR_GRIST_API_TOKEN: ${AIRFLOW_VAR_GRIST_API_TOKEN}
    AIRFLOW_VAR_MES_AIDES_AIRTABLE_KEY: ${AIRFLOW_VAR_MES_AIDES_AIRTABLE_KEY}
    AIRFLOW_VAR_SOLIGUIDE_API_TOKEN: ${AIRFLOW_VAR_SOLIGUIDE_API_TOKEN}

  volumes:
    - ./pipeline/dbt:/opt/airflow/dbt
    - ./pipeline/dags:/opt/airflow/dags
    - ./pipeline/src:/opt/airflow/src

  user: ${AIRFLOW_UID:-50000}:0

  depends_on:
    &airflow-common-depends-on
    airflow-db:
      condition: service_healthy

services:
  airflow-db:
    image: postgres:14
    restart: on-failure
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 5s
      retries: 5
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow

  airflow-webserver:
    <<: *airflow-common
    image: apache/airflow:2.7.0-python3.10
    command: webserver
    restart: on-failure
    ports:
      - ${AIRFLOW_UI_PORT:-8080}:8080
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    image: data-inclusion/pipeline
    build:
      context: pipeline
    command: scheduler
    restart: on-failure
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"'
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    env_file:
      - ./pipeline/defaults.env

  airflow-init:
    <<: *airflow-common
    image: apache/airflow:2.7.0-python3.10
    entrypoint: /bin/bash -c
    user: 0:0
    command:
      - |
        exec /entrypoint airflow version
    environment:
      <<: *airflow-common-environment
      # Additional variables for development only
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: airflow
      _AIRFLOW_WWW_USER_PASSWORD: airflow

  minio:
    image: minio/minio:RELEASE.2022-10-08T20-11-00Z
    command: server /data
    restart: on-failure
    ports:
      - 9000:9000
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio-data:/data

  minio-init:
    image: minio/mc:RELEASE.2022-12-24T15-21-38Z
    entrypoint: /bin/bash -c
    command:
      - |
        mc alias set tmp http://minio:9000 minioadmin minioadmin
        mc mb tmp/data-inclusion-lake
    depends_on:
      - minio

  target-db:
    image: data-inclusion/datawarehouse
    build: datawarehouse
    restart: on-failure
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "data-inclusion" ]
      interval: 5s
      retries: 5
    ports:
      - ${TARGET_POSTGRES_PORT:-5433}:5432
    environment:
      - POSTGRES_DB=data-inclusion
      - POSTGRES_USER=data-inclusion
      - POSTGRES_PASSWORD=data-inclusion
    volumes:
      - pg-data:/var/lib/postgresql/data

  api:
    image: data-inclusion/api
    build: api
    depends_on:
      target-db:
        condition: service_healthy
    restart: on-failure
    ports:
      - ${API_PORT:-8000}:8000
    environment:
      - ENV=${API_ENV:-dev}
      - DEBUG=${API_DEBUG:-False}
      - DATABASE_URL=postgresql://data-inclusion:data-inclusion@target-db:5432/data-inclusion
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY

  siretisation-ui:
    image: data-inclusion/siretisation-ui
    build: siretisation
    depends_on:
      target-db:
        condition: service_healthy
    restart: on-failure
    ports:
      - ${SIRETISATION_UI_PORT:-8005}:8000
    environment:
      - ENV=${SIRETISATION_UI_ENV:-dev}
      - DEBUG=${SIRETISATION_UI_DEBUG}
      - POSTGRES_DB=data-inclusion
      - POSTGRES_USER=data-inclusion
      - POSTGRES_PASSWORD=data-inclusion
      - POSTGRES_HOST=target-db
      - POSTGRES_PORT=5432
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY
      - ALLOWED_HOSTS=127.0.0.1,localhost
      - DJANGO_SUPERUSER_USERNAME=admin
      - DJANGO_SUPERUSER_EMAIL=admin@admin.admin
      - DJANGO_SUPERUSER_PASSWORD=admin
      - ANNUAIRE_ENTREPRISES_API_URL=${ANNUAIRE_ENTREPRISES_API_URL}
    volumes:
      - files-data:/var/www

volumes:
  pg-data:
  minio-data:
  files-data:


networks:
  default:
    name: data-inclusion
