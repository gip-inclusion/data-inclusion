version: "3.9"

x-airflow-common:
  &airflow-common
  build:
    context: ../../pipeline

  environment:
    &airflow-common-environment
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Paris
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    # AIRFLOW__CORE__FERNET_KEY:
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: 'false'
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow:airflow@airflow-db:5432/airflow
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 60
    AIRFLOW__WEBSERVER__WORKERS: 1
    AIRFLOW__WEBSERVER__BASE_URL: http://localhost/airflow

    # Connections
    AIRFLOW_CONN_S3: aws://@/data-inclusion-lake?endpoint_url=http://minio:9000&aws_access_key_id=minioadmin&aws_secret_access_key=minioadmin
    AIRFLOW_CONN_S3_SOURCES: ${AIRFLOW_CONN_S3_SOURCES}
    AIRFLOW_CONN_PG: postgresql://data-inclusion:data-inclusion@target-db:5432/data-inclusion

    # Variables
    AIRFLOW_VAR_DBT_PROJECT_DIR: /opt/airflow/dbt
    AIRFLOW_VAR_BAN_API_URL: ${BAN_API_URL}
    AIRFLOW_VAR_CD35_FILE_URL: ${CD35_FILE_URL}
    AIRFLOW_VAR_CD72_FILE_URL: ${CD72_FILE_URL}
    AIRFLOW_VAR_DATAGOUV_API_KEY: ${DATAGOUV_API_KEY}
    AIRFLOW_VAR_DATAGOUV_API_URL: ${DATAGOUV_API_URL}
    AIRFLOW_VAR_DATAGOUV_DI_DATASET_ID: ${DATAGOUV_DI_DATASET_ID}
    AIRFLOW_VAR_DATAGOUV_DI_RESOURCE_IDS: ${DATAGOUV_DI_RESOURCE_IDS}
    AIRFLOW_VAR_DORA_API_URL: ${DORA_API_URL}
    AIRFLOW_VAR_EMPLOIS_API_TOKEN: ${EMPLOIS_API_TOKEN}
    AIRFLOW_VAR_EMPLOIS_API_URL: ${EMPLOIS_API_URL}
    AIRFLOW_VAR_ETAB_PUB_FILE_URL: ${ETAB_PUB_FILE_URL}
    AIRFLOW_VAR_FINESS_FILE_URL: ${FINESS_FILE_URL}
    AIRFLOW_VAR_INSEE_FIRSTNAME_FILE_URL: ${INSEE_FIRSTNAME_FILE_URL}
    AIRFLOW_VAR_INSEE_COG_DATASET_URL: ${INSEE_COG_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_CONSEILLER_NUMERIQUE_DATASET_URL: ${MEDNUM_CONSEILLER_NUMERIQUE_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_HINAURA_DATASET_URL: ${MEDNUM_HINAURA_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_CD49_DATASET_URL: ${MEDNUM_CD49_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_ASSEMBLEURS_DATASET_URL: ${MEDNUM_ASSEMBLEURS_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_FRANCILIN_DATASET_URL: ${MEDNUM_FRANCILIN_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_FRANCE_TIERS_LIEUX_DATASET_URL: ${MEDNUM_FRANCE_TIERS_LIEUX_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_ANGERS_DATASET_URL: ${MEDNUM_ANGERS_DATASET_URL}
    AIRFLOW_VAR_MEDNUM_FRANCE_SERVICES_DATASET_URL: ${MEDNUM_FRANCE_SERVICES_DATASET_URL}
    AIRFLOW_VAR_MES_AIDES_AIDES_URL: ${MES_AIDES_AIDES_URL}
    AIRFLOW_VAR_MES_AIDES_AIRTABLE_KEY: ${MES_AIDES_AIRTABLE_KEY}
    AIRFLOW_VAR_MES_AIDES_GARAGES_URL: ${MES_AIDES_GARAGES_URL}
    AIRFLOW_VAR_ODSPEP_S3_KEY_PREFIX: ${ODSPEP_S3_KEY_PREFIX}
    AIRFLOW_VAR_SIAO_FILE_URL: ${SIAO_FILE_URL}
    AIRFLOW_VAR_SIRENE_STOCK_ETAB_GEOCODE_FILE_URL: ${SIRENE_STOCK_ETAB_GEOCODE_FILE_URL}
    AIRFLOW_VAR_SIRENE_STOCK_ETAB_HIST_FILE_URL: ${SIRENE_STOCK_ETAB_HIST_FILE_URL}
    AIRFLOW_VAR_SIRENE_STOCK_ETAB_LIENS_SUCCESSION_URL: ${SIRENE_STOCK_ETAB_LIENS_SUCCESSION_URL}
    AIRFLOW_VAR_SIRENE_STOCK_UNITE_LEGALE_FILE_URL: ${SIRENE_STOCK_UNITE_LEGALE_FILE_URL}
    AIRFLOW_VAR_SOLIGUIDE_API_TOKEN: ${SOLIGUIDE_API_TOKEN}
    AIRFLOW_VAR_SOLIGUIDE_API_URL: ${SOLIGUIDE_API_URL}
    AIRFLOW_VAR_UN_JEUNE_UNE_SOLUTION_API_URL: ${UN_JEUNE_UNE_SOLUTION_API_URL}

    # make the data_inclusion package available in editable mode
    PYTHONPATH: $${PYTHONPATH}:/opt/airflow/data-inclusion/src

  volumes:
    - airflow-logs:/opt/airflow/logs
    - ../../pipeline/dbt:/opt/airflow/dbt
    - ../../pipeline/dags:/opt/airflow/dags
    - ../../pipeline/logs:/opt/airflow/logs
    - ../../pipeline/src:/opt/airflow/data-inclusion/src

  user: 0:0

  depends_on:
    &airflow-common-depends-on
    airflow-db:
      condition: service_healthy

services:
  airflow-db:
    image: postgres:14
    restart: on-failure
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 5s
      retries: 5
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash -c
    command:
      - |
        mkdir -p /opt/airflow/logs
        chown -R "0:0" /opt/airflow/logs
        exec /entrypoint airflow version
    environment:
      <<: *airflow-common-environment
      # Additional variables for development only
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: airflow
      _AIRFLOW_WWW_USER_PASSWORD: airflow

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    restart: on-failure
    ports:
      - 8080:8080
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.airflow.rule=Host(`localhost`) && PathPrefix(`/airflow`)"
      - "traefik.http.routers.airflow.entrypoints=http"
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: on-failure
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"'
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  minio:
    image: minio/minio:RELEASE.2022-10-08T20-11-00Z
    command: server /data
    restart: always
    ports:
      - 9000:9000
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio-data:/data

  minio-init:
    image: minio/mc:RELEASE.2022-12-24T15-21-38Z
    entrypoint: /bin/bash -c
    command:
      - |
        mc alias set tmp http://minio:9000 minioadmin minioadmin
        mc mb tmp/data-inclusion-lake
    depends_on:
      - minio

  target-db:
    image: postgis/postgis:14-3.3
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "data-inclusion" ]
      interval: 5s
      retries: 5
    environment:
      - POSTGRES_DB=data-inclusion
      - POSTGRES_USER=data-inclusion
      - POSTGRES_PASSWORD=data-inclusion
    volumes:
      - pg-data:/var/lib/postgresql/data

  api:
    image: data-inclusion/api
    build: ../../api
    depends_on:
      target-db:
        condition: service_healthy
    restart: always
    ports:
      - 8000:8000
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=Host(`localhost`) && PathPrefix(`/api`)"
      - "traefik.http.routers.api.entrypoints=http"
    environment:
      - ENV=prod
      - DEBUG=False
      - DATABASE_URL=postgresql://data-inclusion:data-inclusion@target-db:5432/data-inclusion
      # - SECRET_KEY=${API_SECRET_KEY}
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY
      - ROOT_PATH=/api

  reverse-proxy:
    image: traefik:v2.10
    ports:
      - 80:80
      - 8081:8080
    environment:
      - TRAEFIK_PROVIDERS_DOCKER=true
      - TRAEFIK_PROVIDERS_DOCKER_EXPOSEDBYDEFAULT=false
      # enable the web ui (disabled for prod)
      - TRAEFIK_API_INSECURE=true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro

volumes:
  airflow-logs:
  pg-data:
  minio-data:
  files-data:


networks:
  default:
    name: data-inclusion
